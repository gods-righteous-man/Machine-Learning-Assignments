{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd67a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bootstrapped.bootstrap as bs\n",
    "import bootstrapped.stats_functions as bs_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a423be8",
   "metadata": {},
   "source": [
    "# 1(b) Keep datasets 1 and 2 in folders bending1 and bending 2, as well as datasets 1, 2, and 3 in other folders as test data and other datasets as train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2ebb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestD = []\n",
    "for i in range(1, 3):\n",
    "    TestD.append('../data/AReM/bending1/dataset'+ str(i)+'.csv')\n",
    "for i in range(1, 3):\n",
    "    TestD.append('../data/AReM/bending2/dataset'+ str(i)+'.csv')\n",
    "for i in range(1, 4):\n",
    "    TestD.append('../data/AReM/standing/dataset'+ str(i)+'.csv')\n",
    "for i in range(1, 4):\n",
    "    TestD.append('../data/AReM/walking/dataset'+ str(i)+'.csv')\n",
    "for i in range(1, 4):\n",
    "    TestD.append('../data/AReM/cycling/dataset'+ str(i)+'.csv')\n",
    "for i in range(1, 4):\n",
    "    TestD.append('../data/AReM/sitting/dataset'+ str(i)+'.csv')\n",
    "for i in range(1, 4):\n",
    "    TestD.append('../data/AReM/lying/dataset'+ str(i)+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b660e3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/AReM/bending1/dataset1.csv', '../data/AReM/bending1/dataset2.csv', '../data/AReM/bending2/dataset1.csv', '../data/AReM/bending2/dataset2.csv', '../data/AReM/standing/dataset1.csv', '../data/AReM/standing/dataset2.csv', '../data/AReM/standing/dataset3.csv', '../data/AReM/walking/dataset1.csv', '../data/AReM/walking/dataset2.csv', '../data/AReM/walking/dataset3.csv', '../data/AReM/cycling/dataset1.csv', '../data/AReM/cycling/dataset2.csv', '../data/AReM/cycling/dataset3.csv', '../data/AReM/sitting/dataset1.csv', '../data/AReM/sitting/dataset2.csv', '../data/AReM/sitting/dataset3.csv', '../data/AReM/lying/dataset1.csv', '../data/AReM/lying/dataset2.csv', '../data/AReM/lying/dataset3.csv']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(TestD)\n",
    "print(len(TestD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1de0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainD = []\n",
    "for i in range(3, 8):\n",
    "    TrainD.append('../data/AReM/bending1/dataset'+ str(i)+'.csv')\n",
    "for i in range(3, 7):\n",
    "    TrainD.append('../data/AReM/bending2/dataset'+ str(i)+'.csv')\n",
    "for i in range(4, 16):\n",
    "    TrainD.append('../data/AReM/standing/dataset'+ str(i)+'.csv')\n",
    "for i in range(4, 16):\n",
    "    TrainD.append('../data/AReM/walking/dataset'+ str(i)+'.csv')\n",
    "for i in range(4, 16):\n",
    "    TrainD.append('../data/AReM/cycling/dataset'+ str(i)+'.csv')\n",
    "for i in range(4, 16):\n",
    "    TrainD.append('../data/AReM/sitting/dataset'+ str(i)+'.csv')\n",
    "for i in range(4, 16):\n",
    "    TrainD.append('../data/AReM/lying/dataset'+ str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670ac1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "print(len(TrainD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9030a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9120, 6)\n",
      "(33119, 6)\n"
     ]
    }
   ],
   "source": [
    "actual_testdatacp = pd.DataFrame()\n",
    "actual_traindatacp = pd.DataFrame()\n",
    "\n",
    "col = ['avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "\n",
    "for i in TrainD:\n",
    "    if i == '../data/AReM/bending2/dataset4.csv':\n",
    "        df = pd.read_csv(i, delimiter = ' ', skiprows = 5, header = None, usecols = range(1, 7))\n",
    "    else:\n",
    "        df = pd.read_csv(i, delimiter = ',', skiprows = 5, header = None, usecols = range(1, 7))\n",
    "    actual_traindatacp = actual_traindatacp.append(df, ignore_index = True)\n",
    "\n",
    "for i in TestD:\n",
    "    df = pd.read_csv(i, delimiter = ',', skiprows = 5, header=None, usecols = range(1, 7), names=col)\n",
    "    actual_testdatacp = actual_testdatacp.append(df, ignore_index = True)\n",
    "    \n",
    "print(np.shape(actual_testdatacp))\n",
    "print(np.shape(actual_traindatacp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9e281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362c9651",
   "metadata": {},
   "source": [
    "# c Feature Extraction\n",
    "# Classification of time series usually needs extracting features from them. In this problem, we focus on time-domain features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f234f",
   "metadata": {},
   "source": [
    "# i. Research what types of time-domain features are usually used in time series classification and list them (examples are minimum, maximum, mean, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39287b0d",
   "metadata": {},
   "source": [
    "# Ans: Means, Standard Deviations, Skewness, Curtosis, Maximum and Minimum, First Quartile, Third Quartile are the types of time-domain features that are used in time series classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ea81c",
   "metadata": {},
   "source": [
    "# ii. Extract the time-domain features minimum, maximum, mean, median, stan- dard deviation, first quartile, and third quartile for all of the 6 time series in each instance. You are free to normalize/standardize features or use them directly.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dd9fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = ['bending1', 'bending2', 'cycling', 'lying', 'sitting', 'standing', 'walking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c466dec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/AReM/bending1/dataset1.csv', '../data/AReM/bending1/dataset2.csv', '../data/AReM/bending1/dataset3.csv', '../data/AReM/bending1/dataset4.csv', '../data/AReM/bending1/dataset5.csv', '../data/AReM/bending1/dataset6.csv', '../data/AReM/bending1/dataset7.csv', '../data/AReM/bending2/dataset1.csv', '../data/AReM/bending2/dataset2.csv', '../data/AReM/bending2/dataset3.csv', '../data/AReM/bending2/dataset4.csv', '../data/AReM/bending2/dataset5.csv', '../data/AReM/bending2/dataset6.csv', '../data/AReM/cycling/dataset1.csv', '../data/AReM/cycling/dataset2.csv', '../data/AReM/cycling/dataset3.csv', '../data/AReM/cycling/dataset4.csv', '../data/AReM/cycling/dataset5.csv', '../data/AReM/cycling/dataset6.csv', '../data/AReM/cycling/dataset7.csv', '../data/AReM/cycling/dataset8.csv', '../data/AReM/cycling/dataset9.csv', '../data/AReM/cycling/dataset10.csv', '../data/AReM/cycling/dataset11.csv', '../data/AReM/cycling/dataset12.csv', '../data/AReM/cycling/dataset13.csv', '../data/AReM/cycling/dataset14.csv', '../data/AReM/cycling/dataset15.csv', '../data/AReM/lying/dataset1.csv', '../data/AReM/lying/dataset2.csv', '../data/AReM/lying/dataset3.csv', '../data/AReM/lying/dataset4.csv', '../data/AReM/lying/dataset5.csv', '../data/AReM/lying/dataset6.csv', '../data/AReM/lying/dataset7.csv', '../data/AReM/lying/dataset8.csv', '../data/AReM/lying/dataset9.csv', '../data/AReM/lying/dataset10.csv', '../data/AReM/lying/dataset11.csv', '../data/AReM/lying/dataset12.csv', '../data/AReM/lying/dataset13.csv', '../data/AReM/lying/dataset14.csv', '../data/AReM/lying/dataset15.csv', '../data/AReM/sitting/dataset1.csv', '../data/AReM/sitting/dataset2.csv', '../data/AReM/sitting/dataset3.csv', '../data/AReM/sitting/dataset4.csv', '../data/AReM/sitting/dataset5.csv', '../data/AReM/sitting/dataset6.csv', '../data/AReM/sitting/dataset7.csv', '../data/AReM/sitting/dataset8.csv', '../data/AReM/sitting/dataset9.csv', '../data/AReM/sitting/dataset10.csv', '../data/AReM/sitting/dataset11.csv', '../data/AReM/sitting/dataset12.csv', '../data/AReM/sitting/dataset13.csv', '../data/AReM/sitting/dataset14.csv', '../data/AReM/sitting/dataset15.csv', '../data/AReM/standing/dataset1.csv', '../data/AReM/standing/dataset2.csv', '../data/AReM/standing/dataset3.csv', '../data/AReM/standing/dataset4.csv', '../data/AReM/standing/dataset5.csv', '../data/AReM/standing/dataset6.csv', '../data/AReM/standing/dataset7.csv', '../data/AReM/standing/dataset8.csv', '../data/AReM/standing/dataset9.csv', '../data/AReM/standing/dataset10.csv', '../data/AReM/standing/dataset11.csv', '../data/AReM/standing/dataset12.csv', '../data/AReM/standing/dataset13.csv', '../data/AReM/standing/dataset14.csv', '../data/AReM/standing/dataset15.csv', '../data/AReM/walking/dataset1.csv', '../data/AReM/walking/dataset2.csv', '../data/AReM/walking/dataset3.csv', '../data/AReM/walking/dataset4.csv', '../data/AReM/walking/dataset5.csv', '../data/AReM/walking/dataset6.csv', '../data/AReM/walking/dataset7.csv', '../data/AReM/walking/dataset8.csv', '../data/AReM/walking/dataset9.csv', '../data/AReM/walking/dataset10.csv', '../data/AReM/walking/dataset11.csv', '../data/AReM/walking/dataset12.csv', '../data/AReM/walking/dataset13.csv', '../data/AReM/walking/dataset14.csv', '../data/AReM/walking/dataset15.csv']\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "for i in dsets:\n",
    "    if i == 'bending1':\n",
    "        for j in range(1, 8):\n",
    "            datasets.append('../data/AReM/' + i + '/dataset' + str(j) + '.csv')\n",
    "    elif i == 'bending2':\n",
    "        for j in range(1, 7):\n",
    "            datasets.append('../data/AReM/' + i + '/dataset' + str(j) + '.csv')\n",
    "    else:\n",
    "        for j in range(1, 16):\n",
    "            datasets.append('../data/AReM/' + i + '/dataset' + str(j) + '.csv')\n",
    "            \n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad025b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "table = pd.DataFrame()\n",
    "table_columns = ['min', 'max', 'mean', 'median', 'std', 'first quartile', 'third quartile']\n",
    "bend = ['../data/AReM/bending1/dataset1.csv', '../data/AReM/bending1/dataset2.csv', '../data/AReM/bending1/dataset3.csv', '../data/AReM/bending1/dataset4.csv', '../data/AReM/bending1/dataset5.csv', '../data/AReM/bending1/dataset6.csv', '../data/AReM/bending1/dataset7.csv', '../data/AReM/bending2/dataset1.csv', '../data/AReM/bending2/dataset2.csv', '../data/AReM/bending2/dataset3.csv', '../data/AReM/bending2/dataset4.csv' ,'../data/AReM/bending2/dataset5.csv', '../data/AReM/bending2/dataset6.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf2f2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['min(1)', 'max(1)', 'mean(1)', 'median(1)', 'std(1)', 'first quartile(1)', 'third quartile(1)', 'min(2)', 'max(2)', 'mean(2)', 'median(2)', 'std(2)', 'first quartile(2)', 'third quartile(2)', 'min(3)', 'max(3)', 'mean(3)', 'median(3)', 'std(3)', 'first quartile(3)', 'third quartile(3)', 'min(4)', 'max(4)', 'mean(4)', 'median(4)', 'std(4)', 'first quartile(4)', 'third quartile(4)', 'min(5)', 'max(5)', 'mean(5)', 'median(5)', 'std(5)', 'first quartile(5)', 'third quartile(5)', 'min(6)', 'max(6)', 'mean(6)', 'median(6)', 'std(6)', 'first quartile(6)', 'third quartile(6)']\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    for j in range(len(table_columns)):\n",
    "        temp.append(str(table_columns[j] + '(' + str(i) + ')'))\n",
    "print(temp)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdd289a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min(1)</th>\n",
       "      <th>max(1)</th>\n",
       "      <th>mean(1)</th>\n",
       "      <th>median(1)</th>\n",
       "      <th>std(1)</th>\n",
       "      <th>first quartile(1)</th>\n",
       "      <th>third quartile(1)</th>\n",
       "      <th>min(2)</th>\n",
       "      <th>max(2)</th>\n",
       "      <th>mean(2)</th>\n",
       "      <th>...</th>\n",
       "      <th>first quartile(5)</th>\n",
       "      <th>third quartile(5)</th>\n",
       "      <th>min(6)</th>\n",
       "      <th>max(6)</th>\n",
       "      <th>mean(6)</th>\n",
       "      <th>median(6)</th>\n",
       "      <th>std(6)</th>\n",
       "      <th>first quartile(6)</th>\n",
       "      <th>third quartile(6)</th>\n",
       "      <th>BendingClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.50</td>\n",
       "      <td>1.475428</td>\n",
       "      <td>39.25</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.358604</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.582308</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>42.812812</td>\n",
       "      <td>42.50</td>\n",
       "      <td>1.434054</td>\n",
       "      <td>42.00</td>\n",
       "      <td>43.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.372438</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.600383</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.557210</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.426250</td>\n",
       "      <td>...</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.512971</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179813</td>\n",
       "      <td>43.50</td>\n",
       "      <td>3.666840</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.696042</td>\n",
       "      <td>...</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.523771</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.75</td>\n",
       "      <td>2.241152</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.535979</td>\n",
       "      <td>...</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>19.50</td>\n",
       "      <td>45.33</td>\n",
       "      <td>33.586875</td>\n",
       "      <td>34.25</td>\n",
       "      <td>4.646088</td>\n",
       "      <td>30.25</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.67</td>\n",
       "      <td>4.576562</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7300</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.32</td>\n",
       "      <td>3.259729</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.638534</td>\n",
       "      <td>2.0500</td>\n",
       "      <td>4.3225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>19.75</td>\n",
       "      <td>45.50</td>\n",
       "      <td>34.322750</td>\n",
       "      <td>35.25</td>\n",
       "      <td>4.747524</td>\n",
       "      <td>31.00</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.47</td>\n",
       "      <td>4.456333</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.67</td>\n",
       "      <td>3.432562</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.730921</td>\n",
       "      <td>2.1575</td>\n",
       "      <td>4.5650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>19.50</td>\n",
       "      <td>46.00</td>\n",
       "      <td>34.546229</td>\n",
       "      <td>35.25</td>\n",
       "      <td>4.837247</td>\n",
       "      <td>31.25</td>\n",
       "      <td>37.8125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.47</td>\n",
       "      <td>4.371958</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>3.338125</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1.655016</td>\n",
       "      <td>2.1600</td>\n",
       "      <td>4.3350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>23.50</td>\n",
       "      <td>46.25</td>\n",
       "      <td>34.873229</td>\n",
       "      <td>35.25</td>\n",
       "      <td>4.526997</td>\n",
       "      <td>31.75</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.82</td>\n",
       "      <td>4.380583</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.51</td>\n",
       "      <td>3.424646</td>\n",
       "      <td>3.27</td>\n",
       "      <td>1.689198</td>\n",
       "      <td>2.1700</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>19.25</td>\n",
       "      <td>44.00</td>\n",
       "      <td>34.473188</td>\n",
       "      <td>35.00</td>\n",
       "      <td>4.791706</td>\n",
       "      <td>31.25</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.86</td>\n",
       "      <td>4.359312</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7300</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.340458</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1.697343</td>\n",
       "      <td>2.1200</td>\n",
       "      <td>4.3750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    min(1)  max(1)    mean(1)  median(1)    std(1)  first quartile(1)  \\\n",
       "0    37.25   45.00  40.624792      40.50  1.475428              39.25   \n",
       "1    38.00   45.67  42.812812      42.50  1.434054              42.00   \n",
       "2    35.00   47.40  43.954500      44.33  1.557210              43.00   \n",
       "3    33.00   47.75  42.179813      43.50  3.666840              39.15   \n",
       "4    33.00   45.75  41.678063      41.75  2.241152              41.33   \n",
       "..     ...     ...        ...        ...       ...                ...   \n",
       "83   19.50   45.33  33.586875      34.25  4.646088              30.25   \n",
       "84   19.75   45.50  34.322750      35.25  4.747524              31.00   \n",
       "85   19.50   46.00  34.546229      35.25  4.837247              31.25   \n",
       "86   23.50   46.25  34.873229      35.25  4.526997              31.75   \n",
       "87   19.25   44.00  34.473188      35.00  4.791706              31.25   \n",
       "\n",
       "    third quartile(1)  min(2)  max(2)   mean(2)  ...  first quartile(5)  \\\n",
       "0             42.0000     0.0    1.30  0.358604  ...            33.0000   \n",
       "1             43.6700     0.0    1.22  0.372438  ...            32.0000   \n",
       "2             45.0000     0.0    1.70  0.426250  ...            35.3625   \n",
       "3             45.0000     0.0    3.00  0.696042  ...            30.4575   \n",
       "4             42.7500     0.0    2.83  0.535979  ...            28.4575   \n",
       "..                ...     ...     ...       ...  ...                ...   \n",
       "83            37.0000     0.0   14.67  4.576562  ...            13.7300   \n",
       "84            38.0000     0.0   13.47  4.456333  ...            13.5000   \n",
       "85            37.8125     0.0   12.47  4.371958  ...            14.0000   \n",
       "86            38.2500     0.0   14.82  4.380583  ...            13.7500   \n",
       "87            38.0000     0.0   13.86  4.359312  ...            13.7300   \n",
       "\n",
       "    third quartile(5)  min(6)  max(6)   mean(6)  median(6)    std(6)  \\\n",
       "0               36.00    0.00    1.92  0.570583       0.43  0.582308   \n",
       "1               34.50    0.00    3.11  0.571083       0.43  0.600383   \n",
       "2               36.50    0.00    1.79  0.493292       0.43  0.512971   \n",
       "3               36.33    0.00    2.18  0.613521       0.50  0.523771   \n",
       "4               31.25    0.00    1.79  0.383292       0.43  0.388759   \n",
       "..                ...     ...     ...       ...        ...       ...   \n",
       "83              18.25    0.00    8.32  3.259729       3.11  1.638534   \n",
       "84              17.75    0.00    9.67  3.432562       3.20  1.730921   \n",
       "85              17.75    0.00   10.00  3.338125       3.08  1.655016   \n",
       "86              18.00    0.00    9.51  3.424646       3.27  1.689198   \n",
       "87              17.75    0.43    9.00  3.340458       3.09  1.697343   \n",
       "\n",
       "    first quartile(6)  third quartile(6)  BendingClass  \n",
       "0              0.0000             1.3000             1  \n",
       "1              0.0000             1.3000             1  \n",
       "2              0.0000             0.9400             1  \n",
       "3              0.0000             1.0000             1  \n",
       "4              0.0000             0.5000             1  \n",
       "..                ...                ...           ...  \n",
       "83             2.0500             4.3225             0  \n",
       "84             2.1575             4.5650             0  \n",
       "85             2.1600             4.3350             0  \n",
       "86             2.1700             4.5000             0  \n",
       "87             2.1200             4.3750             0  \n",
       "\n",
       "[88 rows x 43 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = []\n",
    "for i in datasets:\n",
    "    if i == '../data/AReM/bending2/dataset4.csv':\n",
    "        d = pd.read_csv(i, delimiter = ' ', skiprows = 5, header = None, usecols = range(1, 7), names = col)\n",
    "    else:\n",
    "        d = pd.read_csv(i, delimiter = ',', skiprows = 5, header = None, usecols = range(1, 7), names = col)\n",
    "    temp2 = []\n",
    "    if i in bend:\n",
    "        cl.append(1)\n",
    "    else:\n",
    "        cl.append(0)\n",
    "# print(cl)\n",
    "    \n",
    "    for j in range(len(col)):\n",
    "        minv = min(d[col[j]])\n",
    "        maxv = max(d[col[j]])\n",
    "        mean = d[col[j]].mean()\n",
    "        std = np.std(d[col[j]])\n",
    "        first_quart, median, third_quart = d[col[j]].quantile([0.25, 0.5, 0.75])\n",
    "        temp2.extend([minv, maxv, mean, median, std, first_quart, third_quart])\n",
    "#         print(temp2)\n",
    "        \n",
    "    temp3 = pd.DataFrame(temp2).T\n",
    "#     print(temp3)\n",
    "    \n",
    "    table = table.append(temp3, ignore_index=True)\n",
    "    \n",
    "table.columns = temp\n",
    "table.insert(len(temp), 'BendingClass', cl)\n",
    "\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3694dc9",
   "metadata": {},
   "source": [
    "# iii. Estimate the standard deviation of each of the time-domain features you extracted from the data. Then, use Python’s bootstrapped or any other method to build a 90% bootsrap confidence interval for the standard deviation of each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f4b1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min(1)': '(7.3519679994263685,9.762794810280653)',\n",
       " 'max(1)': '(2.796727290527612,4.319555607799246)',\n",
       " 'mean(1)': '(4.712840560562064,6.142850107135247)',\n",
       " 'median(1)': '(3.8107594119462056,4.73078739514275)',\n",
       " 'std(1)': '(1.661797985979915,2.065198088101396)',\n",
       " 'first quartile(1)': '(5.585845193287321,6.811325981972562)',\n",
       " 'third quartile(1)': '(3.6990483908230956,5.519070811191658)',\n",
       " 'min(2)': '(0.0,0.0)',\n",
       " 'max(2)': '(4.891385719720473,5.660305359762078)',\n",
       " 'mean(2)': '(1.2419143167226936,1.6725761607977658)',\n",
       " 'median(2)': '(1.1636790337926899,1.551868934439586)',\n",
       " 'std(2)': '(0.7573032547803125,0.914763267295901)',\n",
       " 'first quartile(2)': '(0.767228862255703,1.045390639419649)',\n",
       " 'third quartile(2)': '(1.7043958729967865,2.153590543467747)',\n",
       " 'min(3)': '(2.550438819181512,3.0212042320889876)',\n",
       " 'max(3)': '(3.7717918190567143,5.070059227760392)',\n",
       " 'mean(3)': '(3.26688603927396,4.708353059366681)',\n",
       " 'median(3)': '(3.717126392107346,4.948169480840454)',\n",
       " 'std(3)': '(0.7122778324349528,1.154415799058845)',\n",
       " 'first quartile(3)': '(3.145017318768403,4.512822889103335)',\n",
       " 'third quartile(3)': '(3.285376455122879,4.663407696230075)',\n",
       " 'min(4)': '(0.0,0.0)',\n",
       " 'max(4)': '(1.8319012316754324,2.2907032598648036)',\n",
       " 'mean(4)': '(1.0363184702452948,1.220093067651042)',\n",
       " 'median(4)': '(0.9093385584887594,1.1608803724926653)',\n",
       " 'std(4)': '(0.41331161731651167,0.4858913218412113)',\n",
       " 'first quartile(4)': '(0.7704512148223813,0.885814112868902)',\n",
       " 'third quartile(4)': '(1.472953110901875,1.6383719009144857)',\n",
       " 'min(5)': '(3.3482879762121587,7.014385920927873)',\n",
       " 'max(5)': '(4.8185649274211855,7.095023950418764)',\n",
       " 'mean(5)': '(3.7962426344075264,6.486110192390407)',\n",
       " 'median(5)': '(4.142598706441285,7.000977547385968)',\n",
       " 'std(5)': '(0.8824192636563942,1.482293819480115)',\n",
       " 'first quartile(5)': '(4.109316644967574,7.321590050196184)',\n",
       " 'third quartile(5)': '(5.142326721849553,7.341208698776366)',\n",
       " 'min(6)': '(0.0,0.0)',\n",
       " 'max(6)': '(2.3104365229218704,2.929445257164604)',\n",
       " 'mean(6)': '(1.1072406353129554,1.2459700860450287)',\n",
       " 'median(6)': '(0.9840128679715732,1.157675726449343)',\n",
       " 'std(6)': '(0.4374483471501701,0.5182910571530807)',\n",
       " 'first quartile(6)': '(0.6423906674309342,0.7971884083624369)',\n",
       " 'third quartile(6)': '(1.4502032688427333,1.6137917108606576)'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "conf_interval = {}\n",
    "c = list(table.columns)\n",
    "c = c[:len(table.columns) - 1]\n",
    "\n",
    "for i in c:\n",
    "    samp = np.random.choice(table[i], size = len(table[i]), replace=True)\n",
    "    obj = bs.bootstrap(samp, stat_func=bs_stats.std, alpha=0.05, num_iterations=1000, is_pivotal = False, iteration_batch_size = 10)\n",
    "    CI = str(obj).split('   ')[1].replace(' ', '').replace(',', ',')\n",
    "    conf_interval[i] = CI\n",
    "    \n",
    "conf_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2f6a9",
   "metadata": {},
   "source": [
    "# iv. Use your judgement to select the three most important time-domain features (one option may be min, mean, and max).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b2ce9b",
   "metadata": {},
   "source": [
    "# Ans: The three most important time-domain features are min , mean and max.\n",
    "\n",
    "<!-- Referred https://stats.stackexchange.com/questions/50807/features-for-time-series-classification -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936b8e7",
   "metadata": {},
   "source": [
    "# 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fefd7c9",
   "metadata": {},
   "source": [
    "# 4. I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. Y = β0 +β1X +β2X2 +β3X3 +ε."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6499b7f",
   "metadata": {},
   "source": [
    "# (a) Suppose that the true relationship between X and Y is linear, i.e. Y = β0 + β1X + ε. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd98de",
   "metadata": {},
   "source": [
    "# Ans: Lower RSS is present in cubic regression in comparison. If linear model had lower RSS then we would not have cubic model with least squares fit. Thus we can say that lower RSS is present in cubic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13895c",
   "metadata": {},
   "source": [
    "# (b) Answer (a) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9f0aa",
   "metadata": {},
   "source": [
    "# Ans: The test data will have high RSS because it will have high variance and can fit according to the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ff043",
   "metadata": {},
   "source": [
    "# (c) SupposethatthetruerelationshipbetweenXandYisnotlinear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de5530",
   "metadata": {},
   "source": [
    "# Ans: Since it can adjust for non-linearity , the training RSS for cubic regression will be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82958b",
   "metadata": {},
   "source": [
    "# (d) Answer (c) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b034f8",
   "metadata": {},
   "source": [
    "# Ans: Cubic regression will still have higher training RSS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
